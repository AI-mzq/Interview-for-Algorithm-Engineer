# 目录

## 第一章 AIGC图像生成领域的主流训练技术

- [1.介绍一下OFT(Orthogonal Finetuning)微调技术](#1.介绍一下OFT(Orthogonal-Finetuning)微调技术)
- [2.图像生成领域主流的微调训练方法有哪些?](#2.图像生成领域主流的微调训练方法有哪些?)
- [3.介绍一下图像生成领域的SFT训练的过程](#3.介绍一下图像生成领域的SFT训练的过程)
- [4.介绍一下图像生成领域的RLHF训练的过程](#4.介绍一下图像生成领域的RLHF训练的过程)
- [5.介绍一下Accelerate加速训练框架](#5.介绍一下Accelerate加速训练框架)
- [6.介绍一下DeepSpeed加速训练框架](#6.介绍一下DeepSpeed加速训练框架)
- [7.如何在Accelerate框架中使用DeepSpeed？](#7.如何在Accelerate框架中使用DeepSpeed？)
- [8.为什么有了Accelerate还需要DeepSpeed？](#8.为什么有了Accelerate还需要DeepSpeed？)
- [9.DeepSpeed中Stage 1/Stage 2/Stage 3有哪些区别？](#9.DeepSpeed中Stage-1/Stage-2/Stage-3有哪些区别？)
- [10.分布式训练框架DeepSpeed相较于Pytorch原生的torchrun有什么优点？](#10.分布式训练框架DeepSpeed相较于Pytorch原生的torchrun有什么优点？)
- [11.如何将训练代码迁移到Accelerate/DeepSpeed框架下？](#11.如何将训练代码迁移到Accelerate/DeepSpeed框架下？)
- [12.图像生成领域主流的分布式训练技术有哪些？](#12.图像生成领域主流的分布式训练技术有哪些？)
- [13.在DDP训练中，n_nodes，world_size，rank，local_rank，n_nodes，node_rank，nproc_per_node参数各代表什么含义？](#13.在DDP训练中，n_nodes，world_size，rank，local_rank，n_nodes，node_rank，nproc_per_node参数各代表什么含义？)
- [14.介绍一下MoE技术及其变体](#14.介绍一下MoE技术及其变体)


### 第二章 AIGC图像生成领域的性能优化技术

- [1.SD中潜在一致性模型LCM、LCM-lora加速原理](#1.SD中潜在一致性模型LCM、LCM-lora加速原理)
- [2.Stable Diffusion的一些加速方法](#2.Stable-Diffusion的一些加速方法)
- [3.DMD2蒸馏是怎么做的？](#3.DMD2蒸馏是怎么做的？)
- [4.目前有哪些主流的图像生成模型量化方法？](#4.目前有哪些主流的图像生成模型量化方法？)
- [5.目前有哪些主流的图像生成模型蒸馏方法？](#5.目前有哪些主流的图像生成模型蒸馏方法？)
- [6.目前有哪些主流的图像生成模型剪枝方法？](#6.目前有哪些主流的图像生成模型剪枝方法？)
- [7.介绍一下OneDiff加速技术的原理](#7.介绍一下OneDiff加速技术的原理)
- [8.介绍一下SVDQuant量化技术的原理](#8.介绍一下SVDQuant量化技术的原理)
- [9.介绍一下xfomers加速技术的原理](#9.介绍一下xfomers加速技术的原理)
- [10.介绍一下Token Merging加速技术的原理](#10.介绍一下Token-Merging加速技术的原理)
- [11.介绍一下TensorRT加速技术的原理](#11.介绍一下TensorRT加速技术的原理)
- [12.介绍一下TeaCache加速技术的原理](#12.介绍一下TeaCache加速技术的原理)
- [13.介绍一下wavespeed加速技术的原理](#13.介绍一下wavespeed加速技术的原理)

### 第三章 AIGC图像生成领域的端侧部署技术

- [1.目前有哪些主流的端侧部署框架？](#1.目前有哪些主流的端侧部署框架？)
- [2.介绍一下NCNN、MNN、TNN等端侧部署框架](#2.介绍一下NCNN、MNN、TNN等端侧部署框架)
- [3.介绍一下ONNXRuntime部署推理框架](#3.介绍一下ONNXRuntime部署推理框架)
- [4.图像生成模型的端侧部署流程是什么样的？](#4.图像生成模型的端侧部署流程是什么样的？)

## 第一章 图像生成领域的主流训练技术正文

<h2 id="1.介绍一下OFT(Orthogonal-Finetuning)微调技术">1.介绍一下OFT(Orthogonal Finetuning)微调技术</h2>

Orthogonal Finetuning (OFT) 是一种在AIGC模型微调过程中使用的技术，旨在通过引入**正交性约束**来减少模型在迁移学习过程中的**灾难性遗忘**（catastrophic forgetting），同时提升微调效率和模型的泛化能力。具有以下特点：
- **原理**：限制参数更新在一个正交子空间内，减少对原始任务的破坏。
- **作用**：抑制灾难性遗忘、提升泛化能力、加速优化过程。
- **优势**：灵活性强、鲁棒性高，适合多任务学习、迁移学习和增量学习。

通过正交矩阵 $R$ 的引入，OFT 有效平衡了模型对旧任务的记忆和新任务的适应，是一种实用且高效的微调方法，适合AIGC领域、传统深度学习领域、自动驾驶领域的广泛应用场景。


### **1. OFT 的核心思想**

OFT 的核心思想是将模型微调时的参数更新限制在一个特定的子空间内，这个子空间由正交矩阵 $R$ 定义。通过这种方式，可以在微调新任务时尽可能保留原始任务的重要信息。

- **传统微调**：
  - 在微调过程中，模型的所有参数都可能被更新，容易导致对原始任务的性能显著下降（灾难性遗忘）。
  
- **OFT 微调**：
  - 通过正交矩阵约束，模型的参数更新仅在特定方向上进行，这样可以减少对原始任务表示的破坏，同时提高对新任务的适配性。

### **2. OFT 的数学表达**

假设模型的原始权重为 $W$ ，新的权重为 $W'$ ，OFT 的更新公式为：

$$
W' = W + \Delta W
$$

其中 $\Delta W$ 被限制在一个正交子空间中：

$$
\Delta W = W \cdot R
$$

- $W$ ：表示原始模型的权重。
- $R$ ：一个正交矩阵（满足 $R^T R = I$ ），定义了允许的更新方向。

### **3. OFT 的关键步骤**

1. **构造正交矩阵 $R$**：
   - $R$ 是随机初始化的正交矩阵，或者通过优化过程学习得到。
   - 正交性（orthogonality）保证了 $R$ 中的列向量是线性独立的，这样更新不会偏离预期方向。

2. **限制更新方向**：
   - 使用 $W \cdot R$ 确保微调的权重变化始终处于一个受限的子空间中。
   - 这种约束可以通过优化正则化项实现。

3. **模型训练**：
   - 在标准的优化过程中加入正交性约束，通常表现为损失函数中的一个额外项：
   
     $$
     \mathcal{L}_{\text{OFT}} = \mathcal{L}_{\text{task}} + \alpha \cdot \| R^T R - I \|_F^2
     $$
     
     - $\mathcal{L}_{\text{task}}$ ：主任务的损失函数。
     - $\| R^T R - I \|_F^2$ ：正交性约束的损失（Frobenius 范数）。
     - $\alpha$ ：超参数，用于平衡两部分损失。

### **4. OFT 的作用**

#### **4.1 减少灾难性遗忘**
- **灾难性遗忘** 是指模型在学习新任务时丧失对原始任务的表现能力。  
- 通过限制参数更新的方向，OFT 可以在适配新任务的同时尽量保留原始任务的表示，从而显著减少灾难性遗忘。

#### **4.2 提升微调效率**
- OFT 的正交约束减少了参数的更新自由度，相当于对更新进行了剪枝。这种方式可以加速优化过程，并在有限的计算资源下获得更好的性能。

#### **4.3 提高模型的泛化能力**
- 正交性约束通过限制权重更新的方向，可以避免过度拟合新任务的数据。这种正则化效果有助于提升模型在新任务上的泛化能力。

#### **4.4 灵活适配不同任务**
- OFT 的正交矩阵 $R$ 可以针对不同任务动态调整，因此可以在多任务学习中实现高效的知识迁移。

### **5. OFT 的优势**

1. **参数更新的灵活性**：
   - OFT 不需要冻结模型的部分权重，而是通过正交子空间限制更新，这样可以更灵活地适应新任务。

2. **减少过拟合的风险**：
   - 正交性约束使模型的更新更具方向性，从而减少了对新任务数据的过拟合。

3. **鲁棒性强**：
   - 在存在较大任务差异的情况下，OFT 能够更稳定地完成新任务的适配。

4. **兼容性高**：
   - OFT 可以与现有的优化技术（如 SGD、Adam）无缝结合，也适用于多种深度学习框架。

### **6. OFT 的实际应用场景**

#### **6.1 迁移学习**
- 在从大规模预训练模型（如 BERT、ResNet）微调到小规模任务时，OFT 可以有效提升性能。

#### **6.2 多任务学习**
- 在同时处理多个任务时，OFT 可以限制参数更新的方向，避免任务之间的干扰。

#### **6.3 增量学习**
- 在模型需要学习新类别或新数据时，OFT 可以防止模型对旧类别的遗忘。

#### **6.4 目标检测与图像分割**
- 在计算机视觉任务中，OFT 可以帮助模型在适配新数据时保留原始特征提取的能力。

### **7. 与其他微调方法的对比**

| **方法**          | **参数更新范围**              | **对灾难性遗忘的抑制** | **实现复杂度** | **适用场景**       |
|-------------------|------------------------------|-----------------------|----------------|-------------------|
| **标准微调**      | 无限制                       | 较差                  | 简单           | 大任务或相似任务   |
| **冻结部分参数**   | 仅更新部分参数               | 中等                  | 较低           | 旧任务重要性高的场景 |
| **L2 正则化微调**  | 全参数更新 + 正则化限制      | 一般                  | 较低           | 泛化能力要求较高   |
| **OFT**           | 全参数更新 + 正交性限制      | 较强                  | 中等           | 灾难性遗忘风险高的场景 |

### **8. OFT 的潜在挑战**

1. **正交矩阵的计算开销**：
   - 正交矩阵 $R$ 的构造和正交性约束的优化会增加一定的计算复杂度。

2. **超参数调节**：
   - 正交性约束的强度 $\alpha$ 需要根据任务进行调整，可能增加调参的复杂性。

3. **对大规模任务的扩展性**：
   - 在特别大的模型（如 GPT-4）或任务中，如何高效地应用 OFT 是一个研究方向。


<h2 id="2.图像生成领域主流的微调训练方法有哪些?">2.图像生成领域主流的微调训练方法有哪些? </h2>


<h2 id="3.介绍一下图像生成领域的SFT训练的过程">3.介绍一下图像生成领域的SFT训练的过程 </h2>


<h2 id="4.介绍一下图像生成领域的RLHF训练的过程">4.介绍一下图像生成领域的RLHF训练的过程 </h2>


<h2 id="5.介绍一下Accelerate加速训练框架">5.介绍一下Accelerate加速训练框架 </h2>


<h2 id="6.介绍一下DeepSpeed加速训练框架">6.介绍一下DeepSpeed加速训练框架 </h2>


<h2 id="7.如何在Accelerate框架中使用DeepSpeed？">7.如何在Accelerate框架中使用DeepSpeed？ </h2>


<h2 id="8.为什么有了Accelerate还需要DeepSpeed？">8.为什么有了Accelerate还需要DeepSpeed？ </h2>


<h2 id="9.DeepSpeed中Stage-1/Stage-2/Stage-3有哪些区别？">9.DeepSpeed中Stage 1/Stage 2/Stage 3有哪些区别？ </h2>


<h2 id="10.分布式训练框架DeepSpeed相较于Pytorch原生的torchrun有什么优点？">10.分布式训练框架DeepSpeed相较于Pytorch原生的torchrun有什么优点？ </h2>


<h2 id="11.如何将训练代码迁移到Accelerate/DeepSpeed框架下？">11.如何将训练代码迁移到Accelerate/DeepSpeed框架下？ </h2>


<h2 id="12.图像生成领域主流的分布式训练技术有哪些？">12.图像生成领域主流的分布式训练技术有哪些？ </h2>


<h2 id="13.在DDP训练中，n_nodes，world_size，rank，local_rank，n_nodes，node_rank，nproc_per_node参数各代表什么含义？">13.在DDP训练中，n_nodes，world_size，rank，local_rank，n_nodes，node_rank，nproc_per_node参数各代表什么含义？ </h2>


<h2 id="14.介绍一下MoE技术及其变体">14.介绍一下MoE技术及其变体 </h2>


---

### 第二章 图像生成领域的性能优化技术

<h2 id="1.SD中潜在一致性模型LCM、LCM-lora加速原理">1.SD中潜在一致性模型LCM、LCM-lora加速原理 </h2>

### 1. CM模型：
OpenAI 的宋飏博士提出的一致性模型（Consistency Model，CM）为解决多步采样问题提供了一个思路。一致性模型并不依赖于预训练的扩散模型，是一种独立的新型生成模型。一致性函数f的核心为这样一个性质：对于任意一个输入xt，经过f输出后，其输出是一致的。

![](./imgs/CM.png)

缺点：一致性模型局限于无条件图片生成，导致包括文生图、图生图等在内的许多实际应用还难以享受这一模型的潜在优势。

### 2. LCM模型
关键技术点：

（1）使用预训练的自动编码器将原始图片编码到潜在空间，在压缩图片中冗余信息的同时让图片在语义上具有更好的一致性；

（2）将无分类器引导（CFG）作为模型的一个输入参数蒸馏进潜在一致性模型中，在享受无分类器引导带来的更好的图片 - 文本的一致性的同时，由于无分类器引导幅度被作为输入参数蒸馏进了潜在一致性模型，从而能够减少推理时的所需要的计算开销；

（3）使用跳步策略来计算一致性损失，大大加快了潜在一致性模型的蒸馏过程。
潜在一致性模型的蒸馏算法的伪代码见下图。

![](./imgs/LCM.png)


<h2 id="2.Stable-Diffusion的一些加速方法">2.Stable Diffusion的一些加速方法</h2>

Stable Diffusion 推理优化主要通过以下几种技术实现加速：

### 1. 基础优化（立即见效）

#### FP16 半精度

```python
pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to("cuda")
```

- **效果**：速度提升 2-3 倍，显存减半

#### 高效调度器

```python
from diffusers import DPMSolverMultistepScheduler
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
# 从 50 步减少到 20 步
```

- **效果**：推理步数减少 60%

### 2. 注意力优化

#### PyTorch 2.0 SDPA（推荐）

- PyTorch 2.0 自动启用，无需额外配置
- 性能与 xFormers 相当

#### xFormers（备选）

```python
pipe.enable_xformers_memory_efficient_attention()
```

- **效果**：速度提升 20-100%，显存显著降低

### 3. 高级优化

#### torch.compile

```python
pipe.unet = torch.compile(pipe.unet, mode="reduce-overhead", fullgraph=True)
```

- **效果**：额外 5-50% 提升（A100）
- **注意**：首次编译需要时间

#### 模型蒸馏

```python
# 使用轻量级模型
pipe = StableDiffusionPipeline.from_pretrained("nota-ai/bk-sdm-small", torch_dtype=torch.float16)
```

- **效果**：模型大小减少 51%，速度提升 43%

### 4. 最佳实践组合

```python
# 1. FP16 + 2. 高效调度器 + 3. PyTorch 2.0
pipe = StableDiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to("cuda")

pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)

# 生成图像
image = pipe("astronaut on mars", num_inference_steps=20).images[0]
```


<h2 id="3.DMD2蒸馏是怎么做的？">3.DMD2蒸馏是怎么做的？</h2>

DMD2（Improved Distribution Matching Distillation）是针对扩散模型蒸馏的一种改进方法，通过一系列技术提升了原始分布匹配蒸馏（DMD）的稳定性和效率，同时能在极少步数下生成高质量图像。相较于原始DMD，DMD2取消了昂贵的回归损失和数据集构建，**引入双时间尺度更新规则**以稳定训练，并**整合GAN损失**以增强分布匹配，最终实现一步或少步生成器的高效训练和推理。

------

### DMD2 核心技术

#### 1. 去除回归损失

DMD2完全取消了原DMD中基于大量噪声-图像对的回归损失，从而**简化训练流程**，减少对昂贵数据集构建的依赖。

#### 2. 双时间尺度更新规则

为了解决由于“fake critic”无法准确估计生成样本分布而导致的训练不稳定问题，DMD2提出了**双时间尺度更新（two time-scale update）**：在每次迭代中，以不同步长分别更新生成器和伪评分网络，保证评分网络能够更快地追踪生成器输出分布，从而实现**训练稳定性**的显著提升。

#### 3. 整合GAN损失

为了增强学生模型对真实分布的学习能力，DMD2在蒸馏过程中**引入GAN损失**，通过判别器区分生成样本与真实图像，将对抗训练信号与分布匹配目标相结合，显著**提升生成图像的质量**和多样性。

#### 4. 模拟多步采样的训练流程

针对训练和推理之间的差异，DMD2设计了新的训练流程，**模拟多步采样**以减少训练-推理不匹配。在训练中，学生生成器不仅学习一步生成，还在隐式目标下感知多步路径信息，从而提高少步生成时的表现。

------

### 算法流程

DMD2的总体训练流程如下：

1. **生成器优化**：利用隐式分布匹配梯度和GAN对抗损失，更新一步或少步生成器。
2. **伪评分网络 & 判别器训练**：在不同时间尺度下，快速更新评分网络以估计生成样本分布，同时训练GAN判别器以区分真假图像。
3. **交替迭代**：重复上述两步，使生成器和评分网络协同进化，直至收敛。

整体流程如图所示，红色箭头表示分布匹配梯度，绿色箭头表示GAN损失，蓝色箭头表示评分网络更新([tianweiy.github.io](https://tianweiy.github.io/dmd2/?ref=aiartweekly&utm_source=chatgpt.com))。


<h2 id="4.图像生成模型的端侧部署流程是什么样的？">4.图像生成模型的端侧部署流程是什么样的？</h2>


<h2 id="5.目前有哪些主流的图像生成模型蒸馏方法？">5.目前有哪些主流的图像生成模型蒸馏方法？</h2>


<h2 id="6.目前有哪些主流的图像生成模型剪枝方法？">6.目前有哪些主流的图像生成模型剪枝方法？</h2>


<h2 id="7.介绍一下OneDiff加速技术的原理">7.介绍一下OneDiff加速技术的原理</h2>


<h2 id="8.介绍一下SVDQuant量化技术的原理">8.介绍一下SVDQuant量化技术的原理</h2>


<h2 id="9.介绍一下xfomers加速技术的原理">9.介绍一下xfomers加速技术的原理</h2>


<h2 id="10.介绍一下Token-Merging加速技术的原理">10.介绍一下Token Merging加速技术的原理</h2>


<h2 id="11.介绍一下TensorRT加速技术的原理">11.介绍一下TensorRT加速技术的原理</h2>


<h2 id="12.介绍一下TeaCache加速技术的原理">12.介绍一下TeaCache加速技术的原理</h2>


<h2 id="13.介绍一下wavespeed加速技术的原理">13.介绍一下wavespeed加速技术的原理</h2>

---

### 第三章 AIGC图像生成领域的端侧部署技术

<h2 id="1.目前有哪些主流的端侧部署框架？">1.目前有哪些主流的端侧部署框架？</h2>


<h2 id="2.介绍一下NCNN、MNN、TNN等端侧部署框架">2.介绍一下NCNN、MNN、TNN等端侧部署框架</h2>


<h2 id="3.介绍一下ONNXRuntime部署推理框架">3.介绍一下ONNXRuntime部署推理框架</h2>


<h2 id="4.图像生成模型的端侧部署流程是什么样的？">4.图像生成模型的端侧部署流程是什么样的？</h2>

---
