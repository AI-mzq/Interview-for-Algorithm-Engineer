# 目录

- [1.目前主流的AI绘画框架有哪些？](#1.目前主流的AI绘画框架有哪些？)
- [2.Stable Diffusion WebUI中Variation seed如何工作的？](#2.Stable-Diffusion-WebUI中Variation-seed如何工作的？)
- [3.介绍一下Stable Diffusion WebUI中不同采样器（比如Euler、DPM++2M等）的原理与使用说明](#3.介绍一下Stable-Diffusion-WebUI中不同采样器（比如Euler、DPM++2M等）的原理与使用说明)
- [4.热门AI绘画插件UltimateSDUpscale的工作原理是什么样的？](#4.热门AI绘画插件UltimateSDUpscale的工作原理是什么样的？)


<h2 id="1.目前主流的AI绘画框架有哪些？">1.目前主流的AI绘画框架有哪些？</h2>

Rocky从AIGC时代的工业界、应用界、竞赛界以及学术界出发，总结了目前主流的AI绘画框架：

1. Diffusers：`diffusers` 库提供了一整套用于训练、推理和评估扩散模型的工具。它的设计目标是简化扩散模型的使用和实验，并提供与 `Hugging Face` 生态系统的无缝集成，包括其 `Transformers` 库和 `Datasets` 库。在AIGC时代中，每次里程碑式的模型发布后，Diffusers几乎都在第一时间进行了原生支持。
![diffusers](./imgs/diffusers图标.png)
2. Stable Diffusion WebUI：`Stable Diffusion Webui` 是一个基于 `Gradio` 框架的GUI界面，可以方便的使用Stable Diffusion系列模型，使用户能够轻松的进行AI绘画。
![Stable Diffusion WebUI](./imgs/WebUI图标.png)
3. ComfyUI：`ComfyUI` 也是一个基于 `Gradio` 框架的GUI界面，与Stable Diffusion WebUI不同的是，ComfyUI框架中侧重构建AI绘画节点和工作流，用户可以通过连接不同的节点来设计和执行AI绘画功能。
![ComfyUI](./imgs/comfyui图标.png)
4. SD.Next：`SD.Next` 基于Stable Diffusion WebUI开发，构建提供了更多高级的功能。在支持Stable Diffusion的基础上，还支持Kandinsky、DeepFloyd IF、Lightning、Segmind、Kandinsky、Pixart-α、Pixart-Σ、Stable Cascade、Würstchen、aMUSEd、UniDiffusion、Hyper-SD、HunyuanDiT等AI绘画模型的使用。
![SDNext](./imgs/SDNext图标.jpeg)
5. Fooocus：`Fooocus` 也是基于 `Gradio` 框架的GUI界面，Fooocus借鉴了Stable Diffusion WebUI和Midjourney的优势，具有离线、开源、免费、无需手动调整、用户只需关注提示和图像等特点。
![Fooocus](./imgs/Fooocus图标.png)


<h2 id="2.Stable-Diffusion-WebUI中Variation-seed如何工作的？">2.Stable Diffusion WebUI中Variation seed如何工作的？</h2>

在Stable Diffusion WebUI中，**Variation Seed**（变体种子）是一个关键参数，用于在保持图像整体结构的前提下，生成与原始种子（Seed）相关联但有细微变化的图像。它的核心思想是通过 **噪声插值** 和 **种子偏移** 等方式控制生成结果的多样性。

通过 **Variation Seed**，用户可以在保留生成图像核心特征的同时，探索细节的多样性，是平衡“稳定性”与“随机性”的重要工具。掌握 Variation Seed 的使用技巧，可显著提升创作效率，尤其在需要批量生成或精细调整的场景中表现突出。

### **1. Variation Seed相关基础概念**

- **Seed（种子）**：  
  在 Stable Diffusion 中，种子决定了生成过程的初始随机噪声。**相同的种子 + 相同参数 + 相同提示词** 会生成完全一致的图像。
- **Variation Seed（变体种子）**：  
  通过引入第二个种子（Variation Seed），并结合 **Variation Strength（变体强度）** 参数，系统会在原始种子和变体种子生成的噪声之间进行插值，从而产生可控的随机变化。

### **2. 核心工作原理**
**Variation Seed 的实现逻辑可以分为以下步骤：**

1. **生成初始噪声**：  
   - 使用 **原始种子（Original Seed）** 生成初始噪声图 $N_{\text{original}}$ 。
   - 使用 **变体种子（Variation Seed）** 生成另一个噪声图 $N_{\text{variation}}$ 。

2. **噪声混合**：  
   根据 **Variation Strength** 参数（取值范围 $[0,1]$ ），对两个噪声图进行线性插值：  

   $N_{\text{final}} = (1 - \alpha) \cdot N_{\text{original}} + \alpha \cdot N_{\text{variation}}$
     
   其中 $\alpha$ 为 Variation Strength 的值：
   - $\alpha=0$ ：完全使用原始种子噪声，结果与原始种子一致。
   - $\alpha=1$ ：完全使用变体种子噪声，等同于直接替换种子。
   - $0 < \alpha <1$ ：混合两种噪声，生成介于两者之间的结果。

3. **去噪生成**：  
   基于混合后的噪声 $N_{\text{final}}$ ，通过扩散模型的去噪过程生成最终图像。由于噪声的微小变化，输出图像会保留原始种子的整体结构，但在细节（如纹理、光照、局部元素）上产生差异。

### **3. 参数交互与效果控制**

- **Variation Strength**：  
  - 控制变化的剧烈程度。较小的值（如 0.2）产生细微调整，较大的值（如 0.8）导致显著差异。
  - **示例**：当生成人像时， $\alpha=0.1$ 可能仅改变发丝细节，而 $\alpha=0.5$ 可能调整面部表情和背景。

- **Resize Seed from Image**：  
  在 WebUI 中，可通过上传图像反推其种子（使用 "Extra" 选项卡），再结合 Variation Seed 生成相似但不同的变体。

### **4. 应用场景与案例**

#### **场景 1：微调生成结果**
- **需求**：生成一张基本满意的图像，但希望调整局部细节（如云层形状、服装纹理）。
- **操作**：  
  1. 固定原始种子，设置 Variation Seed 为新值。  
  2. 逐步增加 Variation Strength（如从 0.1 到 0.3），观察变化是否符合预期。

#### **场景 2：探索多样性**
- **需求**：基于同一提示词生成多张不同但风格统一的图像。
- **操作**：  
  1. 固定原始种子，批量生成时随机设置多个 Variation Seed。  
  2. 设置 Variation Strength 为中等值（如 0.5），平衡一致性与多样性。

#### **场景 3：修复缺陷**
- **需求**：原始种子生成的图像存在局部缺陷（如扭曲的手部），需调整而不改变整体构图。
- **操作**：  
  1. 使用 Inpainting 功能局部修复。  
  2. 结合 Variation Seed 生成多个修复版本，选择最优结果。

### **5. Variation Seed技术扩展应用**
- **噪声空间的连续性**：  
  Stable Diffusion 的噪声空间是连续的，微小的噪声变化会导致生成结果的平滑过渡。这种特性使得 Variation Seed 能够实现可控的多样性。

- **数学扩展**：  
  某些高级实现（如 WebUI 的 "X/Y/Z Plot" 脚本）允许同时测试多个 Variation Seed 和 Strength 组合，生成对比网格图。

- **与 CFG Scale 的交互**：  
  Variation Seed 的变化效果受 **Classifier-Free Guidance Scale（CFG Scale）** 影响。较高的 CFG Scale（如 12）会放大提示词的控制力，可能减弱 Variation Seed 的多样性表现。


### **6. 示例流程（WebUI 操作）**
1. **生成原始图像**：  
   - 输入提示词：`A futuristic cityscape at sunset, neon lights, cyberpunk style`  
   - 设置 Seed：`12345`，生成图像 A。

2. **启用 Variation Seed**：  
   - 勾选 "Enable Variation Seed"，设置 Variation Seed：`67890`，Variation Strength：`0.3`。  
   - 生成图像 B，观察霓虹灯颜色和建筑细节的变化。

3. **调整 Strength**：  
   - 将 Variation Strength 提高到 `0.6`，生成图像 C，对比云层形态和光照方向的差异。


<h2 id="3.介绍一下Stable-Diffusion-WebUI中不同采样器（比如Euler、DPM++2M等）的原理与使用说明">3.介绍一下Stable Diffusion WebUI中不同采样器（比如Euler、DPM++2M等）的原理与使用说明</h2>

在 Stable Diffusion 中，**采样器（Sampler）** 是控制图像生成过程的核心组件，决定了如何从随机噪声中逐步去噪并生成最终图像。不同的采样器通过不同的数学策略平衡生成速度、图像质量和计算资源消耗。

采样器的选择如同“画家选择画笔”——Euler是速写铅笔，DPM++ SDE是精雕细琢的油画笔。理解其原理并匹配场景需求，才能最大化Stable Diffusion的创作潜力。建议从 **DPM++ 2M Karras** 起步，逐步尝试其他采样器，观察参数组合对生成效果的影响。

### **一、采样器基础原理**

#### **1. 什么是采样器？**
采样器本质上是 **微分方程求解器**，用于模拟扩散过程的逆过程（从噪声到图像的逐步去噪）。其核心任务是：  
- 在有限步数内，将高斯噪声转化为符合文本描述的图像。  
- 通过数值方法逼近连续扩散模型的解。

#### **2. 核心指标对比**
| 采样器               | 速度 | 质量 | 最小推荐步数 | 适用场景                     |
|----------------------|------|------|--------------|----------------------------|
| Euler                | 快   | 中   | 20           | 快速生成、概念草图           |
| Euler a (Ancestral)  | 快   | 中   | 20           | 增加随机性，探索多样性       |
| DPM++ 2M Karras      | 中   | 高   | 20           | 高质量细节、人物/复杂场景    |
| DPM++ SDE Karras     | 慢   | 极高 | 25           | 超高精度、艺术创作           |
| DDIM                 | 快   | 中   | 50+          | 确定性生成、种子复现         |
| LMS                  | 快   | 低   | 15           | 极速测试、低显存环境         |
| Heun                 | 中   | 高   | 30           | 平衡速度与质量               |

### **二、主流采样器详解与示例**

#### **1. Euler（欧拉法）**
- **原理**：  
  最简单的 **一阶常微分方程（ODE）求解器**，每一步仅使用当前梯度预测下一步噪声。  
- **特点**：  
  - 计算速度快，显存占用低。  
  - 步数较少时可能出现细节模糊。  
- **示例场景**：  
  - **快速概念验证**：生成 `赛博朋克城市` 的草图（步数20，CFG=7）。  
  - **批量生成**：需要快速生成100张候选图时，用Euler加速。

#### **2. Euler a（带祖先采样的欧拉法）**
- **原理**：  
  在Euler基础上引入 **随机噪声（祖先采样）**，每一步都添加额外随机性。  
- **特点**：  
  - 相同种子下生成结果更多样化。  
  - 步数过多可能导致图像不稳定（如面部扭曲）。  
- **示例场景**：  
  - **创意发散**：生成 `奇幻森林` 时，同一提示词探索不同生物形态。  
  - **艺术抽象**：生成 `水墨画风格山水`，利用随机性增强笔触变化。

#### **3. DPM++ 2M Karras**
- **原理**：  
  基于 **DPM-Solver++** 的多步二阶方法，结合Karras噪声调度策略。  
- **特点**：  
  - 在20-30步内达到高细节水平，适合人物皮肤、毛发等精细纹理。  
  - 显存占用适中，速度略慢于Euler。  
- **示例场景**：  
  - **人像写真**：生成 `电影级肖像，细腻皮肤光影`（步数25，CFG=9）。  
  - **复杂结构**：生成 `机械龙鳞片细节`，保留金属反光与纹理。

#### **4. DPM++ SDE Karras**
- **原理**：  
  在DPM++基础上引入 **随机微分方程（SDE）**，模拟更真实的扩散路径。  
- **特点**：  
  - 生成质量极高，尤其擅长光影层次和复杂材质。  
  - 速度较慢，显存占用较高。  
- **示例场景**：  
  - **商业级渲染**：生成 `珠宝广告图，钻石切面反光`（步数30，CFG=10）。  
  - **超现实艺术**：创作 `熔岩与冰川交融的奇幻景观`。

#### **5. DDIM（Denoising Diffusion Implicit Models）**
- **原理**：  
  非马尔可夫链方法，允许跳步去噪，生成过程具有确定性。  
- **特点**：  
  - 相同种子和参数下结果完全可复现。  
  - 需要较高步数（50+）才能达到最佳效果。  
- **示例场景**：  
  - **精准控制**：生成 `建筑设计线稿`，需多次微调提示词时保持结构一致。  
  - **科研实验**：对比不同提示词对同一噪声种子的影响。

### **三、采样器选择策略**

#### **1. 速度优先场景**
- **推荐采样器**：Euler、LMS  
- **示例**：  
  - 生成 `Q版卡通头像`（步数15，CFG=6），快速测试多种配色方案。  
  - 低显存设备（如4GB GPU）下生成 `简笔画风格插图`。

#### **2. 质量优先场景**
- **推荐采样器**：DPM++ 2M Karras、DPM++ SDE Karras  
- **示例**：  
  - 生成 `商业产品渲染图，皮革纹理与金属logo`（步数25，CFG=12）。  
  - 创作 `超写实风景摄影，晨雾中的雪山`。

#### **3. 平衡场景**
- **推荐采样器**：Heun、DPM++ 2M  
- **示例**：  
  - 生成 `动漫角色立绘`（步数20，CFG=8），兼顾速度与服装细节。  
  - 制作 `游戏场景概念图，中世纪城堡与森林`。

### **四、参数调优技巧**

#### **1. 步数（Steps）与采样器的关系**
- **Euler/DPM++ 2M**：20-30步即可饱和，更多步数无显著提升。  
- **DDIM**：需要50+步才能充分去噪。  

#### **2. CFG Scale 的协同调整**
- **低CFG（3-7）**：适合Euler a，增强随机创意。  
  - 示例：生成 `抽象油画，色彩泼溅`。  
- **高CFG（10-15）**：搭配DPM++ SDE，强化提示词控制。  
  - 示例：生成 `精确医学插图，心脏解剖结构`。

#### **3. 分辨率与采样器选择**
- **低分辨率（512x512）**：Euler/DPM++ 2M 效率更高。  
- **高分辨率（1024x1024+）**：DPM++ SDE 减少伪影。

### **五、实战案例演示**

#### **案例 1：人物肖像生成**
- **目标**：生成 `一位亚洲女性的半身像，柔光摄影，发丝细节清晰`  
- **参数配置**：  
  - 采样器：DPM++ 2M Karras  
  - 步数：25  
  - CFG Scale：8  
  - 分辨率：768x1024  
- **效果对比**：  
  - Euler（20步）：发丝略微模糊，皮肤质感平整。  
  - DPM++ 2M（25步）：发丝分缕可见，面部高光过渡自然。

#### **案例 2：科幻场景设计**
- **目标**：生成 `外星雨林，荧光植物与悬浮岩石`  
- **参数配置**：  
  - 采样器：DPM++ SDE Karras  
  - 步数：30  
  - CFG Scale：11  
  - 分辨率：1024x1024  
- **效果对比**：  
  - Euler a（20步）：植物形态抽象，岩石材质单一。  
  - DPM++ SDE（30步）：植物荧光纹理细腻，岩石表面有侵蚀痕迹。

### **六、常见AIGC面试问题解答**

#### **Q1：为什么DPM++采样器名称中有“2M”或“SDE”？**
- **2M**：表示使用二阶多步方法（2nd-order Multistep）。  
- **SDE**：代表随机微分方程（Stochastic Differential Equation）。

#### **Q2：如何避免采样器导致的“面部扭曲”？**
- 使用DPM++ 2M或Heun，步数≥25。  
- 降低CFG Scale（7-9），避免过度约束。

#### **Q3：哪个采样器最适合生成插画？**
- **扁平风插画**：Euler（步数20，CFG=7）。  
- **厚涂风格**：DPM++ 2M Karras（步数25，CFG=9）。


<h2 id="4.热门AI绘画插件UltimateSDUpscale的工作原理是什么样的？">4.热门AI绘画插件UltimateSDUpscale的工作原理是什么样的？</h2>

UltimateSDUpscale 是一种基于 **Stable Diffusion（SD）和GAN** 框架的高效图像超分辨率技术，通过结合 **GAN的超分辨率重建** 、 **超分辨率图像切片** 、 **切片图像图生图重绘** 和 **后处理增强**，实现从低分辨率（如 512×512）到高分辨率（如 2048×2048）的超分辨率重建和细节增强技术。

### **步骤 1：输入图像进行超分辨率重建**
**目标**：将低分辨率图像进行超分辨率重建，获得高分辨率图像。  
**操作**：  
1. **GAN模型**：将输入图像（如 512×512）使用基于GAN架构的超分模型，获得高分辨率（如 2048×2048）的图像。  

### **步骤 2：超分辨率图像切片**
**目标**：将获得的高分辨率图像进行切片，获得切片图像（如 256×256）。  
**操作**：  
1. **设置切片图像的长宽进行切片**：类似于传统深度学习时代的卷积操作，不断将高分辨率图像进行平滑的切片。  

### **步骤 3：切片图像进行图生图重绘**
**目标**：将切片图像输入SD模型中，进行图生成生图像的操作，从而增强切片图像的细节。  
**操作**：  
1. **SD模型的图生图操作**：将切片图像输入SD模型中进行图生图操作。  

### **步骤 4：切片图像拼接融合与伪影抑制**
**目标**：将切片图像重新拼接融合，并消除超分辨率过程中引入的伪影（如棋盘效应、噪声）。  
**操作**：  
1. **Seams fix技术**：沿着拼接缝隙，进行二次的生成修复。  
2. **频域滤波**：对图像进行小波变换，抑制高频噪声（如色带效应），保留真实细节。   

