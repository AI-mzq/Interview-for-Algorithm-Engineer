# 目录

## 第一章 VIT系列核心基础知识高频考点

- [1.介绍一下VIT的原理](#1.介绍一下VIT的原理)
- [2.VIT的输入端是如何处理图像，将Patch变化为Token的？](#2.VIT的输入端是如何处理图像，将Patch变化为Token的？)
- [3.VIT中的class token的作用是什么？](#3.VIT中的class-token的作用是什么？)
- [4.ViT是如何处理变长序列输入的？](#4.ViT是如何处理变长序列输入的？)

## 第二章 DiT核心基础知识高频考点

- [1.介绍一下DiT模型的基本概念](#1.介绍一下DiT模型的基本概念)
- [2.DiT输入图像的Patch化过程是什么样的？](#2.DiT输入图像的Patch化过程是什么样的？)
- [3.介绍一下FasterDiT](#3.介绍一下FasterDiT)
- [4.介绍一下SiT](#4.介绍一下SiT)
- [5.介绍一下LightningDiT](#5.介绍一下LightningDiT)
- [6.介绍一下DiT架构](#6.介绍一下DiT架构)
- [7.DiT模型中添加控制条件的方式有哪些？各有什么优缺点？](#7.DiT模型中添加控制条件的方式有哪些？各有什么优缺点？)
- [8.介绍一下DiT模型中Block设计方式](#8.介绍一下DiT模型中Block设计方式)
- [9.DiT模型中是否需要加RoPE？为什么？RoPE在其中的作用有哪些？](#9.DiT模型中是否需要加RoPE？为什么？RoPE在其中的作用有哪些？)
- [10.介绍一下DiT模型Block中的In-Context Conditioning机制](#10.介绍一下DiT模型Block中的In-Context-Conditioning机制)


## 第三章 VAE核心基础知识高频考点

- [1.VAE和AE的区别是什么？](#1.VAE和AE的区别是什么？)
- [2.介绍一下自编码器(Auto-Encoder)AE的原理](#2.介绍一下自编码器(Auto-Encoder)AE的原理)
- [3.AE存在什么问题?](#3.AE存在什么问题?)
- [4.介绍一下VAE的原理](#4.介绍一下VAE的原理)
- [5.介绍一下AE，VAE和VQ-VAE三者的区别](#5.介绍一下AE，VAE和VQ-VAE三者的区别)
- [6.VAE生成的图像为什么是模糊的?如何减轻模糊性?](#6.VAE生成的图像为什么是模糊的?如何减轻模糊性?)
- [7.什么是重参数技巧？](#7.什么是重参数技巧？)
- [8.Diffusion Model和VAE中的重参数技巧是如何使用的？](#8.Diffusion-Model和VAE中的重参数技巧是如何使用的？)

## 第四章 SAM系列核心基础知识高频考点

- [1.介绍一下Segment Anything（SAM）模型的原理](#1.介绍一下Segment-Anything（SAM）模型的原理)
- [2.SAM模型的输入Promot类型有哪些？以及它们是如何输入进网络的？](#2.SAM模型的输入Promot类型有哪些？以及它们是如何输入进网络的？)
- [3.SAM模型如何处理目标的分割掩码输出？](#3.SAM模型如何处理目标的分割掩码输出？)
- [4.SAM中的prompt_encoder部分支持几种类型的输入？针对点提示如何编码？](#4.SAM中的prompt_encoder部分支持几种类型的输入？针对点提示如何编码？)
- [5.针对SAM模型的轻量化，有哪些思路？目前的代表性工作有哪些？](#5.针对SAM模型的轻量化，有哪些思路？目前的代表性工作有哪些？)
- [6.SAM2比起SAM有哪些改进？](#6.SAM2比起SAM有哪些改进？)

## 第五章 DINO系列系列核心基础知识高频考点

- [1.介绍一下DINO模型的原理](#1.介绍一下DINO模型的原理)
- [2.DINOv2相比DINO，在架构设计有哪些关键创新点？](#2.DINOv2相比DINO，在架构设计有哪些关键创新点？)
- [3.介绍一下DINOv2训练中的目标函数](#3.介绍一下DINOv2训练中的目标函数)
- [4.介绍一下DINOv3模型](#4.介绍一下DINOv3模型)
- [5.DINOv3的架构设计有哪些关键创新点？](#5.DINOv3的架构设计有哪些关键创新点？)
- [6.DINOv2创建了一个新的高质量数据集,其中处理过程中用到的去重和检索流程是什么样的？](#6.DINOv2创建了一个新的高质量数据集,其中处理过程中用到的去重和检索流程是什么样的？)
- [7.Grounding DINO可以根据文字提示检测任意目标，简述网络的基本架构？](#7.Grounding-DINO可以根据文字提示检测任意目标，简述网络的基本架构？)
- [8.Grounding DINO如何进行零样本迁移，比如要检测电路板中的电容电阻？](#8.Grounding-DINO如何进行零样本迁移，比如要检测电路板中的电容电阻？)
- [9.训练通用目标检测器常会使用多源图像进行训练，如何处理新类别歧视？](#9.训练通用目标检测器常会使用多源图像进行训练，如何处理新类别歧视？)

## 第六章 CLIP系列系列核心基础知识高频考点

- [1.介绍一下CLIP模型的原理](#1.介绍一下CLIP模型的原理)
- [2.CLIP是如何提取文本的？](#2.CLIP是如何提取文本的？)
- [3.CLIP模型有哪些优缺点？](#3.CLIP模型有哪些优缺点？)
- [4.介绍一下CLIP的模型架构、训练方法与损失函数](#4.介绍一下CLIP的模型架构、训练方法与损失函数)
- [5.CLIP有哪些变体？](#5.CLIP有哪些变体？)
- [6.多模态大模型常采用MLP作为视觉映射器，将视觉特征到token一对一地映射到文本空间,如何压缩视觉token量以提升效率？](#6.多模态大模型常采用MLP作为视觉映射器，将视觉特征到token一对一地映射到文本空间,如何压缩视觉token量以提升效率？)


## 第一章 VIT系列核心基础知识高频考点正文

<h2 id="1.介绍一下VIT的原理">1.介绍一下VIT的原理</h2>


<h2 id="2.VIT的输入端是如何处理图像，将Patch变化为Token的？">2.VIT的输入端是如何处理图像，将Patch变化为Token的？</h2>


<h2 id="3.VIT中的class-token的作用是什么？">3.VIT中的class token的作用是什么？</h2>


<h2 id="4.ViT是如何处理变长序列输入的？">4.ViT是如何处理变长序列输入的？</h2>

---

## 第二章 DiT核心基础知识高频考点正文

<h2 id="1.介绍一下DiT模型的基本概念">1.介绍一下DiT模型的基本概念</h2>

DiT（Diffusion Transformer）模型由Meta在2022年首次提出，**其主要是在ViT（Vision Transformer）的架构上进行了优化设计得到的**。**DiT是基于Transformer架构的扩散模型，将扩散模型中经典的U-Net架构完全替换成了Transformer架构**。

同时DiT是一个可扩展的架构，**DiT不仅证明了Transformer思想与扩散模型结合的有效性，并且还验证了Transformer架构在扩散模型上具备较强的Scaling能力**，在稳步增大DiT模型参数量与增强数据质量时，DiT的生成性能稳步提升。其中最大的DiT-XL/2模型在ImageNet 256x256的类别条件生成上达到了当时的SOTA（FID为2.27）性能。

DiT的整体框架并没有采用常规的Pixel Diffusion（像素扩散）架构，而是使用和Stable Diffusion相同的Latent Diffusion（潜变量扩散）架构。

为了获得图像的Latent Feature，所以DiT使用了和SD一样的VAE（基于KL-f8）模型。当我们输入512x512x3的图像时，通过VAE能够压缩生成64x64x4分辨率的Latent特征，这极大地降低了扩散模型的计算复杂度（减少Transformer的token的数量）。

同时，DiT扩散过程的nosie scheduler采用简单的Linear scheduler（timesteps=1000，beta_start=0.0001，beta_end=0.02），这与SD模型是不同的。在SD模型中，所采用的noise scheduler通常是Scaled Linear scheduler。


<h2 id="2.DiT输入图像的Patch化过程是什么样的？">2.DiT输入图像的Patch化过程是什么样的？</h2>

DiT和ViT一样，首先采用一个Patch Embedding来**将输入图像Patch化，主要作用是将VAE编码后的二维特征转化为一维序列，从而得到一系列的图像tokens**，具体如下图所示：

![ViT模型架构示意图](./imgs/ViT模型架构示意图.jpg)

同时，DiT在这个图像Patch化的过程中，设计了patch size这个超参数，它直接决定了图像tokens的大小和数量，从而影响DiT模型的整体计算量。DiT论文中共设置了三种patch size，分别是 $p = 2,4,8$ 。同时和其他Transformers模型一样，在得到图像tokens后，还要加上Positional Embeddings进行位置标记，DiT中采用经典的非学习sin&cosine位置编码技术。具体流程如下图所示：

![DiT中输入图像Patch化的示意图](./imgs/DiT中输入图像Patch化的示意图.png)

输入图像在经过VAE编码器处理后，生成一个Latent特征，我们假设其尺寸为 $I \times I \times C$，其中 $I$ 是Latent特征的宽度或高度， $C$ 是Latent特征的通道数。

接下来，用我们设定的patch size来将Latent特征进行Patch化，假设我们设定 $p = 16$ ，那么这时每个patch的尺寸为 $p \times p$ 。

由于Latent特征的尺寸是 $I \times I$ ，因此在宽度和高度方向可以分别划分出 $\frac{I}{P}$ 个patch。因此，整个Latent特征可以被分成 $\frac{I}{P}$ 个patch。

最后我们将生成的每个尺寸为 $p \times p$ 的patch展平（flatten）成一个向量，其尺寸为 $[1,p\times p\times C]$ ，这些向量就构成了DiT模型的输入tokens，总的来说，生成的token数量为：

$$T = \left(\frac{I}{p}\right)^2 $$

同时每个token的维度为 $d$ ，这是DiT输入的Latent空间维度。

如果我们设置的patch大小较小，那么生成的tokens数量就会较多，这时DiT的输入序列长度会变长，这会增加整体的计算复杂度。


<h2 id="3.介绍一下FasterDiT">3.介绍一下FasterDiT</h2>

FasterDiT 通过两个主要贡献显著加速了扩散变换器（DiT）的训练过程：

1. **SNR 概率密度函数 (PDF) 视角**：FasterDiT 扩展了传统的信号噪声比（SNR）定义，提出通过 SNR 的概率密度函数来分析训练中的数据稳健性。通过对不同训练策略下的 SNR 分布进行分析，可以更直观地理解哪些策略更适合不同的数据，从而优化训练过程，提高训练效率。

2. **新的监督方法**：FasterDiT 引入了结合速度预测和方向监督的监督方法。与传统的噪声预测不同，FasterDiT 预测噪声到数据转化的速度，并且通过余弦相似度监督速度的方向。这种方法加速了模型的训练，使其更快地收敛，并提高了生成效果。

   ![image-20250323205036349](./imgs/Faster_DiT.png)


<h2 id="4.介绍一下SiT">4.介绍一下SiT</h2>

SiT (Scalable Interpolant Transformers) 是一种新型生成模型框架，建立在扩散变换器 (DiT) 的基础上，但引入了更灵活的插值架构，使其在生成高质量图像方面表现更佳。

## 核心特点

1. SiT的核心创新在于重新思考了生成模型中的插值过程。传统扩散模型通常使用固定的前向过程，将数据分布逐步转化为高斯噪声，而SiT则提出了更为灵活的插值框架：

   1. 模块化的设计选择：SiT系统地研究了四个关键组件对生成质量的影响：
      - 时间离散化策略（连续或离散时间）
      - 模型预测方式（速度场或分数预测）
      - 插值函数选择（如Linear或GVP）
      - 采样方法（确定性ODE或随机SDE）
   2. **解耦的扩散系数**：SiT创新性地将扩散系数从前向过程中分离出来，使其可以在推理阶段独立调整，从而更精确地控制KL散度上界，提高生成质量。
   3. **降低传输成本**：实验表明，SiT的插值方式显著降低了路径长度（传输成本），减少了ODE轨迹的曲率，从而减轻了采样过程中的离散化误差。

   ![image-20250323202911475](./imgs/SiT.png)


<h2 id="5.介绍一下LightningDiT">5.介绍一下LightningDiT</h2>

​	LightningDiT解决了潜在扩散模型中的一个根本性矛盾：高维视觉分词器(tokenizer)改善了重建质量，但会显著降低生成性能。这个"优化困境"(optimization dilemma)使现有系统常常在两者之间做出次优妥协。

## 改进方案

1. 视觉基础模型引导的VAE优化
   - 提出VA-VAE(Vision foundation model Aligned VAE)，通过与预训练视觉基础模型对齐来规范高维潜在空间
   - 引入VF Loss(视觉基础模型对齐损失)，包括边际余弦相似度损失和边际距离矩阵相似度损失
   - 为防止过度正则化，在相似度损失中使用边际(margin)机制
   - 通过自适应权重机制平衡不同损失的贡献
2. 扩散模型训练策略优化
   - 计算层面：使用更大批量、调整优化器超参数
   - 扩散优化：整合整流流(Rectified Flow)、对数正态分布采样、速度方向损失
   - 并行训练：实现多节点训练以加速实验验证
3. 架构改进
   - 采用现代Transformer优化：RMSNorm、SwiGLU、旋转位置嵌入(RoPE)
   - 优化patch size策略，确保系统一致性
   - 结合VA-VAE优势，使DiT能更有效地处理高维潜在空间

![image-20250323204405144](./imgs/LightningDiT.png)


<h2 id="6.介绍一下DiT架构">6.介绍一下DiT架构</h2>


<h2 id="7.DiT模型中添加控制条件的方式有哪些？各有什么优缺点？">7.DiT模型中添加控制条件的方式有哪些？各有什么优缺点？</h2>


<h2 id="8.介绍一下DiT模型中Block设计方式">8.介绍一下DiT模型中Block设计方式</h2>


<h2 id="9.DiT模型中是否需要加RoPE？为什么？RoPE在其中的作用有哪些？">9.DiT模型中是否需要加RoPE？为什么？RoPE在其中的作用有哪些？</h2>


<h2 id="10.介绍一下DiT模型Block中的In-Context-Conditioning机制">9.介绍一下DiT模型Block中的In-Context Conditioning机制</h2>

---

## 第三章 VAE核心基础知识高频考点

<h2 id="1.VAE和AE的区别是什么？">1.VAE和AE的区别是什么？</h2>

### 一、AE 与 VAE 基本概念

#### 1. 自编码器（AE）

- **结构**：AE 由编码器（Encoder）和解码器（Decoder）两部分组成，用于将高维输入压缩到低维潜在空间再重构回原始输入。
- **损失函数**：仅包含重构误差（如均方误差或二元交叉熵），训练目标是最小化输入与重构输出间的差距。
- **潜在空间**：映射为确定性向量，编码空间未做正则化，难以从未见向量生成合理样本。

#### 2. 变分自编码器（VAE）

- **结构**：在编码器末端输出潜在分布参数（均值 μ 和对数方差 log σ²），并通过重参数化技巧采样得到隐变量 z，再输入解码器。
- **损失函数**：由重构损失与 KL 散度两部分组成，其中 KL 项度量 q(z|x) 与先验 p(z)（标准正态分布）之差，并对潜在分布进行正则化。
- **潜在空间**：学习到的连续正态分布保证任何从先验采样的 z 都能解码出合理样本，具备随机生成与插值能力。

### 二、核心区别对比

| 特性     | AE                                 | VAE                                |
| -------- | ---------------------------------- | ---------------------------------- |
| 编码方式 | 确定性映射：x → z                  | 概率映射：x → (μ, σ)，z ~ N(μ, σ²) |
| 损失函数 | 仅重构损失                         | 重构损失 + KL 散度                 |
| 潜在空间 | 非正则化、可能出现不连续或稀疏分布 | 正则化为连续正态分布，更易插值     |
| 生成能力 | 对未见向量难以生成合理样本         | 可直接从先验分布采样生成新样本     |

#### 三、应用场景与选型建议

- **AE 适用场景**：
  - 特征提取与降维，如 PCA 替代；
  - 信号或图像去噪，通过重构抑制噪声；
  - 当只需稳定重构，无需从先验生成新样本时，AE 简单高效。
- **VAE 适用场景**：
  - 数据生成与图像插值，利用连续潜在空间在属性间平滑过渡；
  - 属性操作与风格迁移，可在潜在空间中对特征进行加减；
  - 异常检测，通过潜在分布概率评估样本是否偏离训练分布


<h2 id="2.介绍一下自编码器(Auto-Encoder)AE的原理">2.介绍一下自编码器(Auto-Encoder)AE的原理</h2>


<h2 id="3.AE存在什么问题?">3.AE存在什么问题?</h2>


<h2 id="4.介绍一下VAE的原理">4.介绍一下VAE的原理</h2>


<h2 id="5.介绍一下AE，VAE和VQ-VAE三者的区别">5.介绍一下AE，VAE和VQ-VAE三者的区别</h2>


<h2 id="6.VAE生成的图像为什么是模糊的?如何减轻模糊性?">6.VAE生成的图像为什么是模糊的?如何减轻模糊性?</h2>


<h2 id="7.什么是重参数技巧？">7.什么是重参数技巧？</h2>


<h2 id="8.Diffusion-Model和VAE中的重参数技巧是如何使用的？">8.Diffusion Model和VAE中的重参数技巧是如何使用的？</h2>


---

## 第四章 SAM系列核心基础知识高频考点正文

<h2 id="1.介绍一下Segment-Anything（SAM）模型的原理">1.介绍一下Segment Anything（SAM）模型的原理</h2>


<h2 id="2.SAM模型的输入Promot类型有哪些？以及它们是如何输入进网络的？">2.SAM模型的输入Promot类型有哪些？以及它们是如何输入进网络的？</h2>


<h2 id="3.SAM模型如何处理目标的分割掩码输出？">3.SAM模型如何处理目标的分割掩码输出？</h2>


<h2 id="4.SAM中的prompt_encoder部分支持几种类型的输入？针对点提示如何编码？">4.SAM中的prompt_encoder部分支持几种类型的输入？针对点提示如何编码？</h2>


<h2 id="5.针对SAM模型的轻量化，有哪些思路？目前的代表性工作有哪些？">5.针对SAM模型的轻量化，有哪些思路？目前的代表性工作有哪些？</h2>


<h2 id="6.SAM2比起SAM有哪些改进？">6.SAM2比起SAM有哪些改进？</h2>

---

## 第五章 DINO系列系列核心基础知识高频考点正文

<h2 id="1.介绍一下DINO模型的原理">1.介绍一下DINO模型的原理</h2>


<h2 id="2.DINOv2相比DINO，在架构设计有哪些关键创新点？">2.DINOv2相比DINO，在架构设计有哪些关键创新点？</h2>


<h2 id="3.介绍一下DINOv2训练中的目标函数">3.介绍一下DINOv2训练中的目标函数</h2>


<h2 id="4.介绍一下DINOv3模型">4.介绍一下DINOv3模型</h2>


<h2 id="5.DINOv3的架构设计有哪些关键创新点？">5.DINOv3的架构设计有哪些关键创新点？</h2>


<h2 id="6.DINOv2创建了一个新的高质量数据集,其中处理过程中用到的去重和检索流程是什么样的？">6.DINOv2创建了一个新的高质量数据集,其中处理过程中用到的去重和检索流程是什么样的？</h2>


<h2 id="7.Grounding-DINO可以根据文字提示检测任意目标，简述网络的基本架构？">7.Grounding DINO可以根据文字提示检测任意目标，简述网络的基本架构？</h2>


<h2 id="8.Grounding-DINO如何进行零样本迁移，比如要检测电路板中的电容电阻？">8.Grounding DINO如何进行零样本迁移，比如要检测电路板中的电容电阻？</h2>


<h2 id="9.训练通用目标检测器常会使用多源图像进行训练，如何处理新类别歧视？">9.训练通用目标检测器常会使用多源图像进行训练，如何处理新类别歧视？</h2>

---

## 第六章 CLIP系列系列核心基础知识高频考点

<h2 id="1.介绍一下CLIP模型的原理">1.介绍一下CLIP模型的原理</h2>


<h2 id="2.CLIP是如何提取文本的？">2.CLIP是如何提取文本的？</h2>


<h2 id="3.CLIP模型有哪些优缺点？">3.CLIP模型有哪些优缺点？</h2>


<h2 id="4.介绍一下CLIP的模型架构、训练方法与损失函数">4.介绍一下CLIP的模型架构、训练方法与损失函数</h2>


<h2 id="5.CLIP有哪些变体？">5.CLIP有哪些变体？</h2>


<h2 id="6.多模态大模型常采用MLP作为视觉映射器，将视觉特征到token一对一地映射到文本空间,如何压缩视觉token量以提升效率？">6.多模态大模型常采用MLP作为视觉映射器，将视觉特征到token一对一地映射到文本空间,如何压缩视觉token量以提升效率？</h2>

---
